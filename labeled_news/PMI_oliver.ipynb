{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv_new')",
   "metadata": {
    "interpreter": {
     "hash": "4393239baa4fb5f775d2ad25e30167a32ce8e706e8e214ae50de7fbf0a59990f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "f = open('./labelled_sentences.json')\n",
    "data = json.load(f)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data[0]['Label']['classifications'][0]['answer'][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Other cities far from the epicentre have restricted the movement of residents, with a 14-day self-quarantine for people returning to Beijing.'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data[0]['Labeled Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'sentence': Other cities far from the epicentre have restricted the movement of residents with a 14day selfquarantine for people returning to Beijing,\n",
       " 'label': -1}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "punctuation = re.compile('[^\\w\\s]')\n",
    "space = re.compile('  +')\n",
    "\n",
    "clean_data = []\n",
    "for i in range(len(data)):\n",
    "    if bool(data[i]['Label']):\n",
    "\n",
    "\n",
    "        sentence = sp(space.sub(' ', punctuation.sub('', data[i]['Labeled Data'])))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if data[i]['Label']['classifications'][0]['answer'][0]['value'] == 'neutral':\n",
    "            clean_data.append({'sentence': sentence, 'label': 0})\n",
    "        elif data[i]['Label']['classifications'][0]['answer'][0]['value'] == 'negative':\n",
    "            clean_data.append({'sentence': sentence, 'label': -1})\n",
    "        else:\n",
    "            clean_data.append({'sentence': sentence, 'label': 1})\n",
    "    \n",
    "clean_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['after all the newsletter -pron- have run for over a decade motley fool stock advisor have triple the market',\n",
       " 0]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "sentences_lemmaed = []\n",
    "for sentence in clean_data:\n",
    "    words = []\n",
    "    for w in sentence['sentence']:\n",
    "        words.append(w.lemma_.lower())\n",
    "    sentences_lemmaed.append([\" \".join(words), sentence['label']])\n",
    "sentences_lemmaed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1552/1552 [00:00<00:00, 125771.58it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6474"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "words = set()\n",
    "\n",
    "for par in tqdm(sentences_lemmaed):\n",
    "    for w in par[0].split():\n",
    "        words.add(w)\n",
    "\n",
    "words = list(words)\n",
    "        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sentence_count = {-1: 0, 0: 0, 1: 0}\n",
    "\n",
    "for par in tqdm(sentences_lemmaed):\n",
    "    class_paragraph_count[par[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6474/6474 [00:22<00:00, 292.17it/s]\n"
     ]
    }
   ],
   "source": [
    "word_class_sentence_count = {}\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_class_sentence_count[word] = {-1: 0, 0: 0, 1: 0}\n",
    "    for par in sentences_lemmaed:\n",
    "        if word in par[0].split():\n",
    "            word_class_sentence_count[word][par[1]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sentence_count = {}\n",
    "for k, v in word_class_sentence_count.items():\n",
    "    word_sentence_count[k] = sum(v.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1552"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "total = len(sentences_lemmaed)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/6474 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'class_sentence_count' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a574ff3dc3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         pmi[word][-1] = math.log(\n\u001b[1;32m      9\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mword_class_sentence_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             (class_sentence_count[-1] / total))\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         pmi[word][-1] = math.log(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_sentence_count' is not defined"
     ]
    }
   ],
   "source": [
    "pmi = {}\n",
    "\n",
    "# p(w|c)\n",
    "for word in tqdm(words):\n",
    "    pmi[word] = {}\n",
    "    \n",
    "    if word_class_sentence_count[word][-1] != 0:\n",
    "        pmi[word][-1] = math.log(\n",
    "            (word_class_sentence_count[word][-1] / total) / \n",
    "            (class_sentence_count[-1] / total))\n",
    "    else:\n",
    "        pmi[word][-1] = math.log(\n",
    "            (1 / total) / \n",
    "            (class_sentence_count[-1] / total))\n",
    "\n",
    "\n",
    "    if word_class_sentence_count[word][0] != 0:\n",
    "        pmi[word][0] = math.log(\n",
    "            (word_class_sentence_count[word][0] / total) / \n",
    "            (class_sentence_count[0] / total))\n",
    "    else:\n",
    "        pmi[word][0] = math.log(\n",
    "            (1 / total) / \n",
    "            (class_sentence_count[0] / total))\n",
    "\n",
    "    \n",
    "        \n",
    "    if word_class_sentence_count[word][1] != 0:\n",
    "        pmi[word][1] = math.log(\n",
    "            (word_class_sentence_count[word][1] / total) / \n",
    "            (class_sentence_count[1] / total))\n",
    "    else:\n",
    "        pmi[word][1] = math.log(\n",
    "            (1 / total) / \n",
    "            (class_sentence_count[1] / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = {}\n",
    "\n",
    "for word, values in pmi.items():\n",
    "    S[word] = values[1] - values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              sent  freq\n",
       "ensure    3.061468    14\n",
       "small     2.966158    15\n",
       "thank     2.455333     6\n",
       "dose      2.455333     7\n",
       "research  2.455333    15\n",
       "...            ...   ...\n",
       "down     -2.010576    45\n",
       "confirm  -2.044477    35\n",
       "concern  -2.109016    23\n",
       "resident -2.109016    29\n",
       "outbreak -2.139787    41\n",
       "\n",
       "[6474 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ensure</th>\n      <td>3.061468</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>small</th>\n      <td>2.966158</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>thank</th>\n      <td>2.455333</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>dose</th>\n      <td>2.455333</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>research</th>\n      <td>2.455333</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>down</th>\n      <td>-2.010576</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>confirm</th>\n      <td>-2.044477</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>concern</th>\n      <td>-2.109016</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>resident</th>\n      <td>-2.109016</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>outbreak</th>\n      <td>-2.139787</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n<p>6474 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "s_df = pd.DataFrame.from_dict(S, orient='index')\n",
    "s_df.columns = ['sent']\n",
    "freq = pd.DataFrame.from_dict(word_sentence_count, orient='index')\n",
    "freq.columns = ['freq']\n",
    "s_df = s_df.join(freq)\n",
    "s_df.sort_values('sent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sent    0.663573\n",
       "freq    3.000000\n",
       "Name: negative, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "s_df.loc['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_lexicon_file = './vader_lexicon.txt'\n",
    "vader_lexicon = {}\n",
    "with open(vader_lexicon_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        vader_lexicon[line.split('\\t')[0]] = float(line.split('\\t')[1])\n",
    "vader_words = list(vader_lexicon.keys())\n",
    "\n",
    "s_new = s_df[~s_df.index.isin(vader_words)].copy()\n",
    "s_com = s_df[s_df.index.isin(vader_words)].copy()\n",
    "\n",
    "s_com['vader'] = s_com.apply(lambda x: vader_lexicon.get(x.name), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nIndex: 0 entries\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   sent    0 non-null      float64\n 1   freq    0 non-null      int64  \n 2   vader   0 non-null      float64\ndtypes: float64(2), int64(1)\nmemory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "s_com.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_com_filter = s_com[s_com['freq']>100].copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Code/NLP2590/venv_new/lib/python3.9/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/NLP2590/venv_new/lib/python3.9/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m_ipython_display_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_on_display\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/NLP2590/venv_new/lib/python3.9/site-packages/plotly/io/_renderers.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnbformat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4.2.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m                 \u001b[0;34m\"Mime type rendering requires nbformat>=4.2.0 but it is not installed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "px.scatter(s_com_filter, x='vader', y='sent', text='index', size='freq',\n",
    "           labels={'vader': 'Vader score', 'sent': 'Customized score'}, \n",
    "           title='Comparison of Lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}